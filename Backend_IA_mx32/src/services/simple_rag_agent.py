"""
Agente RAG simplificado con Cerebras
Versi√≥n simplificada sin LangChain complejo
"""

import os
import json
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import asyncio

from src.models.chatbot import UserContext, UserRole, MessageRole, ChatResponseStructured
from src.services.cerebras_client import get_cerebras_client
from src.rag_service import rag_service

logger = logging.getLogger(__name__)

class SimpleRAGAgent:
    """
    Agente RAG simplificado que usa Cerebras
    """
    
    def __init__(self):
        # Configurar Cerebras
        self.cerebras_client = get_cerebras_client()
        
        # Memoria simple
        self.conversation_memory: Dict[str, List[Dict[str, str]]] = {}
        
    def _get_conversation_memory(self, session_id: str) -> List[Dict[str, str]]:
        """Obtiene la memoria de conversaci√≥n"""
        if session_id not in self.conversation_memory:
            self.conversation_memory[session_id] = []
        return self.conversation_memory[session_id]
    
    def _extract_entities_from_message(self, message: str) -> List[str]:
        """Extrae entidades del mensaje del usuario"""
        entities = []
        
        # Palabras clave relacionadas con M√©xico
        mexico_keywords = [
            "mexico", "m√©xico", "estados", "estado", "ciudad", "municipio",
            "seguridad", "economia", "econom√≠a", "desarrollo", "infraestructura",
            "educacion", "educaci√≥n", "salud", "empleo", "pobreza", "crimen"
        ]
        
        message_lower = message.lower()
        for keyword in mexico_keywords:
            if keyword in message_lower:
                entities.append(keyword)
        
        return entities
    
    def _check_mexico_restriction(self, message: str) -> tuple[bool, str]:
        """Verifica si la pregunta es sobre datos de M√©xico o externos"""
        message_lower = message.lower()
        
        # Palabras clave que indican pa√≠ses o regiones externas
        external_countries = [
            "estados unidos", "usa", "eeuu", "united states", "america",
            "canada", "canad√°", "brasil", "argentina", "colombia", "chile",
            "peru", "per√∫", "venezuela", "ecuador", "bolivia", "paraguay",
            "uruguay", "espa√±a", "spain", "francia", "france", "alemania",
            "germany", "italia", "italy", "china", "japon", "jap√≥n",
            "corea", "korea", "india", "rusia", "russia", "australia",
            "nueva zelanda", "new zealand", "reino unido", "uk", "inglaterra"
        ]
        
        # Verificar si menciona pa√≠ses externos
        for country in external_countries:
            if country in message_lower:
                return False, f"Lo siento, pero solo puedo proporcionar informaci√≥n sobre datos de M√©xico. Mi base de datos contiene √∫nicamente informaci√≥n de los 32 estados mexicanos que puedes visualizar en las gr√°ficas de la plataforma. ¬øTe gustar√≠a que te ayude con informaci√≥n sobre alg√∫n estado espec√≠fico de M√©xico? üá≤üáΩ"
        
        # Verificar si es una pregunta sobre M√©xico o estados mexicanos
        mexico_indicators = [
            "mexico", "m√©xico", "estados", "estado", "jalisco", "nuevo le√≥n",
            "ciudad de m√©xico", "cdmx", "yucat√°n", "quintana roo", "campeche",
            "tabasco", "chiapas", "oaxaca", "veracruz", "puebla", "tlaxcala",
            "hidalgo", "quer√©taro", "san luis potos√≠", "tamaulipas", "coahuila",
            "durango", "zacatecas", "aguascalientes", "guanajuato", "michoac√°n",
            "guerrero", "morelos", "mexico", "baja california", "baja california sur",
            "sonora", "sinaloa", "nayarit", "colima"
        ]
        
        has_mexico_context = any(indicator in message_lower for indicator in mexico_indicators)
        
        if not has_mexico_context:
            return False, "Solo puedo ayudarte con informaci√≥n sobre los 32 estados de M√©xico. Mi base de datos contiene datos espec√≠ficos de seguridad, econom√≠a, infraestructura, educaci√≥n y otros par√°metros de los estados mexicanos que puedes ver en las gr√°ficas de la plataforma. ¬øSobre qu√© estado de M√©xico te gustar√≠a saber? üá≤üáΩ"
        
        return True, ""
    
    async def process_chat_with_rag(
        self,
        messages: List[Dict[str, str]],
        user_context: UserContext,
        api_data: Optional[Dict] = None
    ) -> ChatResponseStructured:
        """
        Procesa un mensaje de chat usando RAG y Cerebras
        """
        try:
            # Obtener el √∫ltimo mensaje
            last_message = messages[-1] if messages else {"role": "user", "content": ""}
            user_message = last_message["content"]
            
            # Verificar restricci√≥n de M√©xico
            is_mexico_related, restriction_message = self._check_mexico_restriction(user_message)
            if not is_mexico_related:
                return ChatResponseStructured(
                    response=restriction_message,
                    confidence=1.0,
                    sources=["Sistema de restricciones MX32"],
                    suggested_actions=[
                        "Ver datos de estados mexicanos",
                        "Explorar par√°metros disponibles",
                        "Consultar informaci√≥n de seguridad",
                        "Analizar datos econ√≥micos"
                    ],
                    follow_up_questions=[
                        "¬øSobre qu√© estado de M√©xico te gustar√≠a saber?",
                        "¬øQu√© par√°metro te interesa analizar?",
                        "¬øTe gustar√≠a ver una comparaci√≥n entre estados?"
                    ],
                    model_used="cerebras-gpt-oss-120b",
                    session_id=user_context.session_id or "default",
                    memory_used=True,
                    rag_enabled=False
                )
            
            # Obtener memoria de conversaci√≥n
            session_id = user_context.session_id or "default"
            conversation_memory = self._get_conversation_memory(session_id)
            
            # Extraer entidades
            entities = self._extract_entities_from_message(user_message)
            
            # Determinar si usar RAG
            use_rag = user_context.rag_enabled and any(keyword in user_message.lower() for keyword in [
                "estado", "jalisco", "mexico", "an√°lisis", "datos", "par√°metro", "rag"
            ])
            
            if use_rag:
                # Usar RAG para obtener datos
                estado = user_context.current_state or "jalisco"  # Default
                try:
                    rag_data = await rag_service.consulta_estado_con_rag(estado)
                    
                    # Crear prompt con datos RAG
                    system_prompt = f"""Eres un experto en an√°lisis de datos de M√©xico con acceso a informaci√≥n RAG actualizada.
                    
                    Datos RAG disponibles para {estado}:
                    {json.dumps(rag_data, ensure_ascii=False, indent=2)}
                    
                    Responde la pregunta del usuario bas√°ndote en estos datos reales y actualizados.
                    Siempre menciona que la informaci√≥n proviene de datos RAG actualizados.
                    """
                    
                    response_text = await self.cerebras_client.generate_response(
                        system_prompt=system_prompt,
                        user_message=user_message,
                        temperature=0.7,
                        max_tokens=2000
                    )
                    
                    rag_enabled = True
                    sources = ["Base de datos MX32", "RAG Analysis", "Cerebras AI"]
                    confidence = 0.9
                    
                except Exception as e:
                    logger.error(f"Error en RAG: {e}")
                    # Fallback sin RAG
                    system_prompt = "Eres un experto en an√°lisis de datos de M√©xico. Responde la pregunta del usuario."
                    response_text = await self.cerebras_client.generate_response(
                        system_prompt=system_prompt,
                        user_message=user_message,
                        temperature=0.7,
                        max_tokens=2000
                    )
                    rag_enabled = False
                    sources = ["Base de datos MX32", "Cerebras AI"]
                    confidence = 0.8
            else:
                # Usar solo Cerebras sin RAG
                system_prompt = """Eres un experto en an√°lisis de datos de M√©xico. 
                Responde la pregunta del usuario de manera profesional y √∫til.
                Siempre menciona que solo tienes informaci√≥n sobre los 32 estados de M√©xico."""
                
                response_text = await self.cerebras_client.generate_response(
                    system_prompt=system_prompt,
                    user_message=user_message,
                    temperature=0.7,
                    max_tokens=2000
                )
                
                rag_enabled = False
                sources = ["Base de datos MX32", "Cerebras AI"]
                confidence = 0.8
            
            # Generar acciones sugeridas
            suggested_actions = []
            if user_context.current_state:
                suggested_actions.append(f"Ver datos completos de {user_context.current_state}")
                suggested_actions.append(f"Comparar {user_context.current_state} con otros estados")
            
            if "seguridad" in entities:
                suggested_actions.append("Ver an√°lisis detallado de seguridad")
                suggested_actions.append("Comparar indicadores de seguridad")
            
            if "economia" in entities or "econom√≠a" in entities:
                suggested_actions.append("Analizar indicadores econ√≥micos")
                suggested_actions.append("Ver datos de empleo")
            
            # Generar preguntas de seguimiento
            follow_up_questions = []
            if user_context.current_state:
                follow_up_questions.append(f"¬øTe gustar√≠a comparar {user_context.current_state} con otros estados?")
                follow_up_questions.append(f"¬øQu√© otros par√°metros te interesan de {user_context.current_state}?")
            
            if "seguridad" in entities:
                follow_up_questions.append("¬øTe interesa analizar las tendencias de seguridad?")
            
            # Actualizar memoria
            conversation_memory.append({"role": "user", "content": user_message})
            conversation_memory.append({"role": "assistant", "content": response_text})
            
            # Mantener solo los √∫ltimos 10 intercambios
            if len(conversation_memory) > 20:
                conversation_memory = conversation_memory[-20:]
                self.conversation_memory[session_id] = conversation_memory
            
            return ChatResponseStructured(
                response=response_text,
                confidence=confidence,
                sources=sources,
                suggested_actions=suggested_actions[:5],
                follow_up_questions=follow_up_questions[:3],
                model_used="cerebras-gpt-oss-120b",
                session_id=session_id,
                memory_used=True,
                rag_enabled=rag_enabled,
                entity_data={
                    "states_mentioned": entities,
                    "entities": {"general": entities},
                    "intent": "rag_analysis" if rag_enabled else "general_analysis"
                }
            )
            
        except Exception as e:
            logger.error(f"Error procesando chat con RAG: {e}")
            return ChatResponseStructured(
                response="Lo siento, ocurri√≥ un error al procesar tu consulta. Por favor, int√©ntalo de nuevo.",
                confidence=0.0,
                sources=[],
                model_used="cerebras-gpt-oss-120b",
                session_id=user_context.session_id or "default",
                rag_enabled=False
            )

# Instancia global del agente
_simple_rag_agent = None

def get_simple_rag_agent() -> SimpleRAGAgent:
    """Obtiene la instancia global del agente RAG simplificado"""
    global _simple_rag_agent
    if _simple_rag_agent is None:
        _simple_rag_agent = SimpleRAGAgent()
    return _simple_rag_agent
